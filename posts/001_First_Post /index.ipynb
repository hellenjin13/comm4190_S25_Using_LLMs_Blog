{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e07f0f68-4cf6-4863-8f33-5b9b6c917ba2",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Testing LLMs: Can They Really Understand Idioms?\"\n",
    "description: \"A blog about the experiments I will be doing with the LLM to see if they can undertsand idioms like humans do\"\n",
    "author: \"Hellen Jin\"\n",
    "date: \"2/4/2024\"\n",
    "categories:\n",
    "  - LLMs\n",
    "  - Figurative Language \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "311ca234-8c66-488e-88ce-ea413c34bb99",
   "metadata": {},
   "source": [
    "**Idioms!!**\n",
    "\n",
    "<img src=\"idiom.png\" width=\"50%\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72baf3f3-4184-4ee7-8cba-6003cfd92900",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Testing LLMs: Can They Really Understand Idiom? \n",
    "\n",
    "* Introduction: \n",
    "\n",
    "> Large Language Models (LLMs) have advanced rapidly, demonstrating impressive capabilities in language generation, text summarization, and creative writing. However, one area where they still face challenges is in understanding and using idioms effectively. In this post, we will analyze how LLMs interpret idiomatic expressions, whether they recognize them in different contexts, and how well they use idioms in responses.\n",
    "\n",
    "* Experiment: Prompting the LLM with Idioms\n",
    "> To evaluate an LLM’s ability to handle idioms, I tested it using three different types of prompts:\n",
    ">1. Literal vs. Figurative Meaning – Asking the model to define idioms and then use them in a sentence.\n",
    ">2. Contextual Understanding – Providing sentences with idioms and asking the model to interpret their meanings.\n",
    ">3. Creative Application – Asking the model to generate short stories or dialogues incorporating idioms naturally.\n",
    "\n",
    "* Results & Observations\n",
    ">1. Literal vs. Figurative Meaning: The LLM performed well in defining common idioms like *“kick the bucket”* and *“burn the midnight oil”*. However, it occasionally struggled with less common idioms, providing overly literal definitions.\n",
    "   >- Example:\n",
    "     - **Prompt:** “What does ‘spill the beans’ mean?”\n",
    "     - **Response:** “It means to reveal a secret.” (CORRECT) \n",
    "     - **Prompt:** “What does ‘barking up the wrong tree’ mean?”\n",
    "     - **Response:** “It means to misunderstand a situation and pursue the wrong course of action.” (CORRECT) \n",
    "\n",
    ">2. **Contextual Understanding:** When idioms were embedded in sentences, the LLM usually understood their meaning correctly. However, in cases where the idiom had multiple possible interpretations, the model sometimes provided a contextually incorrect answer.\n",
    "   >- Example:\n",
    "     - **Sentence:** “John thought he could get a promotion by befriending the CEO, but he was barking up the wrong tree.”\n",
    "     - **LLM’s interpretation:** “John made a mistake in trying to befriend the CEO for a promotion.” (CORRECT) \n",
    "     - **Sentence:** “After the argument, Lisa broke the ice with a joke.”\n",
    "     - **LLM’s interpretation:** “Lisa shattered something made of ice.” (Misinterpretation)\n",
    "\n",
    ">3. **Creative Application:** When asked to generate a story using idioms naturally, the LLM inserted them but sometimes in an awkward or forced way. This suggests that while the model understands idioms, it may struggle with their nuanced use in organic conversation.\n",
    "   >- Example:\n",
    "     - **Prompt:** “Write a short story where a detective uses idioms while solving a case.”\n",
    "     - **Excerpt:** *“Detective Hardy knew time was of the essence. ‘We have to catch the suspect red-handed!’ he said. But his partner was beating around the bush, hesitant to investigate the crime scene. Hardy sighed. ‘Come on, let’s cut to the chase.’”*\n",
    "     - Verdict: Acceptable but a bit cliché in its use of idioms.\n",
    "\n",
    "* Conclusion\n",
    ">While LLMs have a strong grasp of idiomatic meanings and can recognize idioms in most contexts, their application of idioms in generated text can sometimes feel unnatural. They excel at defining and interpreting idioms but occasionally falter in using them fluidly in storytelling and casual dialogue. Future improvements in contextual learning and training on conversational nuances may help bridge this gap, making AI-generated language even more human-like.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da20246-bbe2-4d88-b9f1-b0409a544f0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8518a433-f997-4562-960e-b65acaf8ec8d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
